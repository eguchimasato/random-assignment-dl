{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import graph_alg3 as ga\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_knopp(matrix, max_iter=1000, tol=1e-6):\n",
    "    for _ in range(max_iter):\n",
    "        matrix /= matrix.sum(axis=1, keepdims=True)  # 行ごとに正規化\n",
    "        matrix /= matrix.sum(axis=0, keepdims=True)  # 列ごとに正規化\n",
    "        \n",
    "        if np.allclose(matrix.sum(axis=1), 1, atol=tol) and np.allclose(matrix.sum(axis=0), 1, atol=tol):\n",
    "            break\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def generate_permutation_array(N, num_goods):\n",
    "    P = np.zeros((N, num_goods))\n",
    "    for i in range(N): \n",
    "        P[i] = np.random.permutation(num_goods)\n",
    "    \n",
    "    return P\n",
    "\n",
    "\n",
    "def sample_ranking(N, num_goods):\n",
    "        \"\"\" \n",
    "        Samples ranked lists\n",
    "        Arguments\n",
    "            N: Number of samples\n",
    "            prob: Probability of truncation       \n",
    "        Returns:\n",
    "            Ranked List of shape [N, Num_agents]\n",
    "        \"\"\"\n",
    "        P = generate_permutation_array(N, num_goods) + 1\n",
    "        \n",
    "        return P / num_goods\n",
    "\n",
    "    \n",
    "def generate_batch(batch_size, num_goods):\n",
    "        \"\"\"\n",
    "        Samples a batch of data from training\n",
    "        Arguments\n",
    "            batch_size: number of samples\n",
    "            prob: probability of truncation\n",
    "        Returns\n",
    "            P: Agent's preferences, \n",
    "                P_{ij}: How much Agent-i prefers to be Good-j\n",
    "        \"\"\"\n",
    "        N = batch_size * num_goods\n",
    "        P = sample_ranking(N, num_goods).reshape(-1, num_goods, num_goods)\n",
    "        return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 100  # 繰り返し回数\n",
    "batch_size = 1\n",
    "num_goods = 4\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    start_time = time.perf_counter()  # 開始時刻の計測\n",
    "    \n",
    "    # ランダムな割り当て行列の生成と処理\n",
    "    randomassignment = np.random.rand(batch_size, num_goods, num_goods)\n",
    "    RandomAssignment = np.array([sinkhorn_knopp(matrix) for matrix in randomassignment])\n",
    "    \n",
    "    # 好み（preferences）の生成\n",
    "    preferences = generate_batch(batch_size, num_goods)\n",
    "    \n",
    "    # numpy配列から PyTorch の tensor に変換\n",
    "    P = torch.tensor(RandomAssignment, dtype=torch.float32)\n",
    "    Preferences = torch.tensor(preferences, dtype=torch.float32)\n",
    "    \n",
    "    # 入力データの表示\n",
    "    print(f\"Iteration {i+1}\")\n",
    "    print(\"P: \", P)\n",
    "    print(\"Preferences: \", Preferences)\n",
    "    \n",
    "    # グラフアルゴリズムによる処理\n",
    "    ev = ga.compute_ev(P, Preferences)\n",
    "    violations, cycles = ev.execute_all_cycles_batch()\n",
    "    print(\"Violations:\", violations)\n",
    "    end_time = time.perf_counter()  # 終了時刻の計測\n",
    "    print(f\"Time taken for iteration {i+1}: {end_time - start_time:.6f} sec\")\n",
    "    print(\"Cycles:\", cycles)\n",
    "    #print(\"CPU Count:\", cpucount)\n",
    "    \n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

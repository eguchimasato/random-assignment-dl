{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing efficiency violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class compute_ev:\n",
    "    def __init__(self, num_goods, P, preferences):\n",
    "        \"\"\"\n",
    "        P: batch_size x n x n の二重確率行列 (torch.Tensor)\n",
    "        preferences: n x n の選好行列 (torch.Tensor)\n",
    "                     各行 i はエージェント i の選好を表し、値が大きいほど好む\n",
    "        \"\"\"\n",
    "        self.P = P.clone().detach().cpu()\n",
    "        if isinstance(preferences, np.ndarray):\n",
    "            preferences = torch.tensor(preferences, dtype=torch.float32)\n",
    "        self.preferences = preferences.clone().detach().float()\n",
    "        self.n = num_goods\n",
    "\n",
    "    def build_graph(self, Q, preferences):\n",
    "        \"\"\"\n",
    "        Q: 現在の n x n 二重確率行列 (torch.Tensor)\n",
    "        オブジェクトを頂点とするグラフを構築する。\n",
    "        エッジ (a -> b) は、あるエージェント i が a を b より好む（preferences[i, a] > preferences[i, b]）\n",
    "        かつ Q[i, b] > 0 である場合に追加する。\n",
    "        エッジには (b, i, Q[i, b]) の情報を記録する。\n",
    "        \"\"\"\n",
    "\n",
    "        graph = {a: [] for a in range(self.n)}\n",
    "        for a in range(self.n):\n",
    "            for b in range(self.n):\n",
    "                if a == b:\n",
    "                    continue\n",
    "                for i in range(self.n):\n",
    "                    if preferences[i, a].item() > preferences[i, b].item() and Q[i, b].item() > 0:\n",
    "                        graph[a].append((b, i, Q[i, b].item()))\n",
    "                        # 同じ (a, b) ペアについて、最初に条件を満たしたエージェントを witness とする\n",
    "                        break\n",
    "        return graph\n",
    "\n",
    "    def find_cycle(self, graph):\n",
    "        \"\"\"\n",
    "        DFS を用いてグラフ中のサイクル（閉路）を探索する。\n",
    "        サイクルが見つかった場合は、サイクルを構成するエッジのリストを返す。\n",
    "        各エッジは (from_object, to_object, witness_agent, available_probability) のタプル。\n",
    "        サイクルがなければ None を返す。\n",
    "        \"\"\"\n",
    "        visited = set()\n",
    "        rec_stack = []  # 各要素は (vertex, edge_info)。最初の頂点は edge_info=None\n",
    "\n",
    "        def dfs(v):\n",
    "            visited.add(v)\n",
    "            rec_stack.append((v, None))\n",
    "            for (nbr, agent, avail) in graph[v]:\n",
    "                for idx, (node, _) in enumerate(rec_stack):\n",
    "                    if node == nbr:\n",
    "                        cycle_edges = []\n",
    "                        # rec_stack[idx+1:] に記録されているエッジ情報がサイクル内のエッジ\n",
    "                        for j in range(idx + 1, len(rec_stack)):\n",
    "                            edge = rec_stack[j][1]\n",
    "                            if edge is not None:\n",
    "                                cycle_edges.append(edge)\n",
    "                        cycle_edges.append((v, nbr, agent, avail))\n",
    "                        return cycle_edges\n",
    "                if nbr not in visited:\n",
    "                    rec_stack.append((v, (v, nbr, agent, avail)))\n",
    "                    result = dfs(nbr)\n",
    "                    if result is not None:\n",
    "                        return result\n",
    "                    rec_stack.pop()\n",
    "            rec_stack.pop()\n",
    "            return None\n",
    "\n",
    "        for vertex in range(self.n):\n",
    "            if vertex not in visited:\n",
    "                cycle = dfs(vertex)\n",
    "                if cycle is not None:\n",
    "                    return cycle\n",
    "        return None\n",
    "\n",
    "    def divide_P_matrices(self, idx):\n",
    "        Q = self.P[idx].clone()\n",
    "        return Q\n",
    "    \n",
    "    def divide_preferences_matrices(self, idx):\n",
    "        preferences = self.preferences[idx].clone()\n",
    "        return preferences\n",
    "\n",
    "    def execute_all_cycles(self, Q, preferences):\n",
    "        \"\"\"\n",
    "        idx: バッチ内のインデックス\n",
    "        対応する n x n 行列に対してサイクル交換を実施し、違反量 (violation) を計算する。\n",
    "        \"\"\"\n",
    "        # 抽出: バッチ内の idx 番目の n x n 行列\n",
    "        cycles_exchanges = []\n",
    "        violation = 0.0\n",
    "        while True:\n",
    "            graph = self.build_graph(Q, preferences)\n",
    "            cycle = self.find_cycle(graph)\n",
    "            if cycle is None:\n",
    "                break\n",
    "            # サイクル内の各エッジの利用可能な確率の最小値を epsilon とする\n",
    "            epsilons = [edge[3] for edge in cycle]\n",
    "            epsilon = min(epsilons)\n",
    "            violation += epsilon\n",
    "            # サイクル内の各エッジについて交換を実施\n",
    "            for (a, b, agent, avail) in cycle:\n",
    "                Q[agent, b] -= epsilon\n",
    "                Q[agent, a] += epsilon\n",
    "            cycles_exchanges.append((cycle, epsilon))\n",
    "        return violation\n",
    "\n",
    "    def execute_all_cycles_batch(self):\n",
    "        \"\"\"\n",
    "        バッチ内の各 n x n 行列に対して execute_all_cycles を計算し、違反量 (violation) をまとめる。\n",
    "        結果はバッチサイズ x 1 のテンソルとなる。\n",
    "        \"\"\"\n",
    "        batch_size = self.P.shape[0]\n",
    "\n",
    "        # P行列とpreferences行列を分割\n",
    "        P_list = [self.divide_P_matrices(i) for i in range(batch_size)]\n",
    "        preferences_list = [self.divide_preferences_matrices(i) for i in range(batch_size)]\n",
    "\n",
    "        with mp.Pool(mp.cpu_count()) as pool:\n",
    "            # 各プロセスに対してバッチ内の異なる idx を渡して並列実行\n",
    "            violations = pool.starmap(self.execute_all_cycles, zip(P_list, preferences_list))\n",
    "        # 結果を torch.Tensor に変換し、形状を (batch_size, 1) にする\n",
    "        violations = torch.tensor(violations, dtype=torch.float32).unsqueeze(1)\n",
    "        return violations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating appropriate examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_knopp(matrix, max_iter=1000, tol=1e-6):\n",
    "    for _ in range(max_iter):\n",
    "        matrix /= matrix.sum(axis=1, keepdims=True)  # 行ごとに正規化\n",
    "        matrix /= matrix.sum(axis=0, keepdims=True)  # 列ごとに正規化\n",
    "        \n",
    "        if np.allclose(matrix.sum(axis=1), 1, atol=tol) and np.allclose(matrix.sum(axis=0), 1, atol=tol):\n",
    "            break\n",
    "    return matrix\n",
    "\n",
    "def generate_permutation_array(N, num_goods):\n",
    "    P = np.zeros((N, num_goods))\n",
    "    for i in range(N): P[i] = np.random.permutation(num_goods)\n",
    "    return P\n",
    "\n",
    "def sample_ranking(N, num_goods):\n",
    "        \"\"\" \n",
    "        Samples ranked lists\n",
    "        Arguments\n",
    "            N: Number of samples\n",
    "            prob: Probability of truncation       \n",
    "        Returns:\n",
    "            Ranked List of shape [N, Num_agents]\n",
    "        \"\"\"\n",
    "        P = generate_permutation_array(N, num_goods) + 1\n",
    "        \n",
    "        return P/num_goods\n",
    "\n",
    "def generate_batch(batch_size, num_goods):\n",
    "        \"\"\"\n",
    "        Samples a batch of data from training\n",
    "        Arguments\n",
    "            batch_size: number of samples\n",
    "            prob: probability of truncation\n",
    "        Returns\n",
    "            P: Agent's preferences, \n",
    "                P_{ij}: How much Agent-i prefers to be Good-j\n",
    "        \"\"\"\n",
    "        N = batch_size * num_goods\n",
    "        \n",
    "        P = sample_ranking(N, num_goods)\n",
    "        \n",
    "        P = P.reshape(-1, num_goods, num_goods)                           \n",
    "                \n",
    "        return P\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:  tensor([[[0.1942, 0.2139, 0.3251, 0.2668],\n",
      "         [0.1476, 0.1902, 0.2323, 0.4299],\n",
      "         [0.2986, 0.1005, 0.3740, 0.2269],\n",
      "         [0.3596, 0.4954, 0.0686, 0.0764]],\n",
      "\n",
      "        [[0.0133, 0.2868, 0.4729, 0.2270],\n",
      "         [0.4589, 0.1961, 0.1998, 0.1451],\n",
      "         [0.1232, 0.3489, 0.1379, 0.3901],\n",
      "         [0.4045, 0.1682, 0.1894, 0.2379]]])\n",
      "Preferences:  tensor([[[0.5000, 0.7500, 0.2500, 1.0000],\n",
      "         [0.5000, 0.7500, 1.0000, 0.2500],\n",
      "         [0.7500, 0.2500, 1.0000, 0.5000],\n",
      "         [0.7500, 0.5000, 1.0000, 0.2500]],\n",
      "\n",
      "        [[0.7500, 0.5000, 0.2500, 1.0000],\n",
      "         [0.2500, 0.5000, 1.0000, 0.7500],\n",
      "         [1.0000, 0.7500, 0.5000, 0.2500],\n",
      "         [0.2500, 0.7500, 0.5000, 1.0000]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreferences: \u001b[39m\u001b[38;5;124m\"\u001b[39m, Preferences)\n\u001b[1;32m     11\u001b[0m ev\u001b[38;5;241m=\u001b[39m compute_ev(num_goods, P, Preferences)\n\u001b[0;32m---> 12\u001b[0m violations \u001b[38;5;241m=\u001b[39m \u001b[43mev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_all_cycles_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP: \u001b[39m\u001b[38;5;124m\"\u001b[39m, P)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreferences: \u001b[39m\u001b[38;5;124m\"\u001b[39m, Preferences)\n",
      "Cell \u001b[0;32mIn[39], line 120\u001b[0m, in \u001b[0;36mcompute_ev.execute_all_cycles_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m preferences_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivide_preferences_matrices(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)]\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(mp\u001b[38;5;241m.\u001b[39mcpu_count()) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# 各プロセスに対してバッチ内の異なる idx を渡して並列実行\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     violations \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstarmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_all_cycles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mP_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferences_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# 結果を torch.Tensor に変換し、形状を (batch_size, 1) にする\u001b[39;00m\n\u001b[1;32m    122\u001b[0m violations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(violations, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py:540\u001b[0m, in \u001b[0;36mPool._handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 540\u001b[0m     \u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    542\u001b[0m     job, idx \u001b[38;5;241m=\u001b[39m task[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/connection.py:206\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_writable()\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_bytes(\u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/torch/multiprocessing/reductions.py:607\u001b[0m, in \u001b[0;36mreduce_storage\u001b[0;34m(storage)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot pickle meta storage; try pickling a meta tensor instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m get_sharing_strategy() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_system\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 607\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_share_filename_cpu_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m     cache_key \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    609\u001b[0m     rebuild \u001b[38;5;241m=\u001b[39m rebuild_storage_filename\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/torch/storage.py:450\u001b[0m, in \u001b[0;36m_share_memory_lock_protected.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# If we acquired the storage lock here and we're done working on it\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# we can now release it and free the entry.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m to_free \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;66;03m# Ensure that the cdata from the storage didn't change and only\u001b[39;00m\n\u001b[1;32m    456\u001b[0m         \u001b[38;5;66;03m# the data_ptr did.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.13/site-packages/torch/storage.py:529\u001b[0m, in \u001b[0;36mUntypedStorage._share_filename_cpu_\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;129m@_share_memory_lock_protected\u001b[39m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_share_filename_cpu_\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_share_filename_cpu_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Broken pipe"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "batch_size = 2\n",
    "num_goods = 4\n",
    "randomassignment = np.random.rand(batch_size, 4, 4)\n",
    "RandomAssignment = np.array([sinkhorn_knopp(matrix) for matrix in randomassignment])\n",
    "preferences = generate_batch(batch_size, num_goods)\n",
    "P = torch.tensor(RandomAssignment, dtype=torch.float32)\n",
    "Preferences = torch.tensor(preferences, dtype=torch.float32)\n",
    "print(\"P: \", P)\n",
    "print(\"Preferences: \", Preferences)\n",
    "ev= compute_ev(num_goods, P, Preferences)\n",
    "violations = ev.execute_all_cycles_batch()\n",
    "print(\"P: \", P)\n",
    "print(\"Preferences: \", Preferences)\n",
    "print(violations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbool\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bool'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import random\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pref(n,m):\n",
    "    row = torch.linspace(1/m, 1, m)  # 1行分の値を生成\n",
    "    pref = torch.stack([row[torch.randperm(m)] for _ in range(n)])\n",
    "    return pref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial_dictatorship(n, m, preferences, order):\n",
    "    # 各順列での配分行列\n",
    "    allocation = torch.zeros((n, m))\n",
    "    available_goods = torch.ones(m)  # 各財が未配分\n",
    "    \n",
    "    for i in order:\n",
    "        # 参加者 i の選好を取得\n",
    "        pref = preferences[i]\n",
    "        # 選好の高い順に財を割り当てる\n",
    "        for good in torch.argsort(pref, descending=True):\n",
    "            if available_goods[good] > 0:\n",
    "                allocation[i][good] = 1\n",
    "                available_goods[good] = 0\n",
    "                break  # 一つの財を割り当てたら終了\n",
    "    \n",
    "    return allocation\n",
    "\n",
    "def random_serial_dictatorship(n, m, preferences):\n",
    "    # 全順列の平均配分行列\n",
    "    total_allocation = torch.zeros((n, m))\n",
    "    \n",
    "    # 全順列を生成\n",
    "    for order in itertools.permutations(range(n)):\n",
    "        sd_allocation = serial_dictatorship(n, m, preferences, order)\n",
    "        total_allocation += sd_allocation\n",
    "    \n",
    "    # 平均を取る\n",
    "    allocation = total_allocation / torch.tensor(math.factorial(n), dtype=torch.float)\n",
    "    \n",
    "    return allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilistic_serial(n, m, preferences, allocation_step=0.001):\n",
    "    # 各参加者の割り当て配分行列\n",
    "    allocation = torch.zeros((n, m))\n",
    "    # 各財の残り割合（全員が分配を完了するまで1.0）\n",
    "    available_goods = torch.ones(m)\n",
    "    \n",
    "    # 分配プロセス: 各参加者が0から徐々に割り当てを行う\n",
    "    while available_goods.sum() > 0:\n",
    "        # 各参加者が少しずつ配分\n",
    "        for i in range(n):\n",
    "            # 参加者iの選好に基づき、可能な限り財を取得\n",
    "            for good in torch.argsort(preferences[i], descending=True):\n",
    "                if available_goods[good] > 0:\n",
    "                    # 配分率（allocation_stepずつ割り当て）\n",
    "                    allocation_rate = min(available_goods[good], allocation_step)\n",
    "                    allocation[i][good] += allocation_rate\n",
    "                    available_goods[good] -= allocation_rate\n",
    "                    # 財が尽きたら次の財に移る\n",
    "                    if available_goods[good] <= 0:\n",
    "                        available_goods[good] = 0  # 残りが0未満にならないように補正\n",
    "                    break  # 次の参加者に移る\n",
    "    return allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferences:\n",
      "tensor([[1.0000, 0.7500, 0.5000, 0.2500],\n",
      "        [1.0000, 0.7500, 0.5000, 0.2500],\n",
      "        [1.0000, 0.7500, 0.2500, 0.5000],\n",
      "        [0.7500, 1.0000, 0.2500, 0.5000]])\n",
      "Allocation(RSD):\n",
      "tensor([[0.3333, 0.1667, 0.4167, 0.0833],\n",
      "        [0.3333, 0.1667, 0.4167, 0.0833],\n",
      "        [0.3333, 0.1667, 0.0833, 0.4167],\n",
      "        [0.0000, 0.5000, 0.0833, 0.4167]])\n",
      "Allocation(PS):\n",
      "tensor([[3.3400e-01, 1.6700e-01, 5.0000e-01, 0.0000e+00],\n",
      "        [3.3301e-01, 1.6601e-01, 5.0000e-01, 0.0000e+00],\n",
      "        [3.3300e-01, 1.6700e-01, 0.0000e+00, 5.0001e-01],\n",
      "        [0.0000e+00, 5.0000e-01, 9.3246e-06, 5.0000e-01]])\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "m = 4\n",
    "preferences = torch.tensor([[1, 0.75, 0.5, 0.25],[1, 0.75, 0.5, 0.25], [1, 0.75, 0.25, 0.5], [0.75, 1, 0.25, 0.5]])\n",
    "\n",
    "print(\"Preferences:\")\n",
    "print(preferences)\n",
    "\n",
    "allocation = random_serial_dictatorship(n, m, preferences)\n",
    "print(\"Allocation(RSD):\")\n",
    "print(allocation)\n",
    "\n",
    "allocation = probabilistic_serial(n, m, preferences)\n",
    "print(\"Allocation(PS):\")\n",
    "print(allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferences:\n",
      "tensor([[1.0000, 0.7500, 0.5000, 0.2500],\n",
      "        [1.0000, 0.7500, 0.5000, 0.2500],\n",
      "        [0.7500, 1.0000, 0.5000, 0.2500],\n",
      "        [0.7500, 1.0000, 0.2500, 0.5000]])\n",
      "Allocation(RSD):\n",
      "tensor([[0.4167, 0.0833, 0.3333, 0.1667],\n",
      "        [0.4167, 0.0833, 0.3333, 0.1667],\n",
      "        [0.0833, 0.4167, 0.3333, 0.1667],\n",
      "        [0.0833, 0.4167, 0.0000, 0.5000]])\n",
      "Allocation(PS):\n",
      "tensor([[5.0001e-01, 0.0000e+00, 3.3301e-01, 1.6600e-01],\n",
      "        [5.0000e-01, 9.3246e-06, 3.3300e-01, 1.6700e-01],\n",
      "        [0.0000e+00, 5.0000e-01, 3.3400e-01, 1.6700e-01],\n",
      "        [0.0000e+00, 5.0000e-01, 0.0000e+00, 5.0001e-01]])\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "m = 4\n",
    "preferences = torch.tensor([[1, 0.75, 0.5, 0.25],[1, 0.75, 0.5, 0.25], [0.75, 1, 0.5, 0.25], [0.75, 1, 0.25, 0.5]])\n",
    "\n",
    "print(\"Preferences:\")\n",
    "print(preferences)\n",
    "\n",
    "allocation = random_serial_dictatorship(n, m, preferences)\n",
    "print(\"Allocation(RSD):\")\n",
    "print(allocation)\n",
    "\n",
    "allocation = probabilistic_serial(n, m, preferences)\n",
    "print(\"Allocation(PS):\")\n",
    "print(allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.7500, 0.5000, 0.2500],\n",
      "        [1.0000, 0.7500, 0.5000, 0.2500],\n",
      "        [0.7500, 1.0000, 0.2500, 0.5000],\n",
      "        [0.2500, 0.7500, 0.5000, 1.0000]])\n",
      "tensor([[0.0586, 0.3948, 0.2248, 0.1714],\n",
      "        [0.5842, 0.1339, 0.2008, 0.3363],\n",
      "        [0.2291, 0.4171, 0.1775, 0.0111],\n",
      "        [0.1281, 0.0542, 0.3968, 0.4812]])\n"
     ]
    }
   ],
   "source": [
    "def make_pref(n,m):\n",
    "    row = torch.linspace(1/m, 1, m)  # 1行分の値を生成\n",
    "    pref = torch.stack([row[torch.randperm(m)] for _ in range(n)])\n",
    "    return pref\n",
    "\n",
    "def generate_random_doubly_stochastic_matrix(n, m):\n",
    "    # ランダムな行列を生成\n",
    "    matrix = torch.rand(n, m)\n",
    "    \n",
    "    # 行和が1になるように正規化\n",
    "    row_sums = matrix.sum(dim=1, keepdim=True)\n",
    "    matrix = matrix / row_sums\n",
    "    \n",
    "    # 列和が1になるように正規化\n",
    "    col_sums = matrix.sum(dim=0, keepdim=True)\n",
    "    matrix = matrix / col_sums\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "\n",
    "preferences = make_pref(4,4)\n",
    "print(preferences)\n",
    "# 例としてn=4, m=4のランダムな二重確率行列を生成\n",
    "random_doubly_stochastic_matrix = generate_random_doubly_stochastic_matrix(4, 4)\n",
    "print(random_doubly_stochastic_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m initial_owners \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(m)  \u001b[38;5;66;03m# 各エージェントが一意のアイテムを所有しているone-hot表現\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# アルゴリズム実行\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m final_allocation \u001b[38;5;241m=\u001b[39m \u001b[43mtop_trading_cycles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreferences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_owners\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_allocation)\n",
      "Cell \u001b[0;32mIn[25], line 48\u001b[0m, in \u001b[0;36mtop_trading_cycles\u001b[0;34m(preferences, initial_owners)\u001b[0m\n\u001b[1;32m     46\u001b[0m     allocation[agent_id] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(m)  \u001b[38;5;66;03m# 以前の所有をクリア\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     allocation[agent_id, item_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 新しい所有をセット\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mowner_of\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem_id\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# アイテムを市場から除去\u001b[39;00m\n\u001b[1;32m     50\u001b[0m remaining_agents \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(cycle)  \u001b[38;5;66;03m# 交換完了エージェントを削除\u001b[39;00m\n\u001b[1;32m     51\u001b[0m cycle_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "def top_trading_cycles(preferences, initial_owners):\n",
    "    \"\"\"\n",
    "    preferences: torch.Tensor (n x m の行列, 各行はエージェントの各財への選好（値が大きいほど好ましい）)\n",
    "    initial_owners: torch.Tensor (n x m の行列, 各行はエージェントの所有アイテムを示すone-hotベクトル)\n",
    "    \"\"\"\n",
    "    n, m = preferences.shape\n",
    "    agents = list(range(n))  # エージェントを0,1,2,...,n-1として扱う\n",
    "    allocation = torch.zeros_like(initial_owners)  # 最終的なマッチング結果（one-hot行列）\n",
    "    remaining_agents = set(agents)  # 交換が完了していないエージェント\n",
    "    \n",
    "    # 初期所有者のマッピング（財のインデックス -> エージェント）\n",
    "    owner_of = {torch.argmax(initial_owners[i]).item(): i for i in range(n)}\n",
    "    \n",
    "    while remaining_agents:\n",
    "        # 1. 各エージェントが最も好むアイテムを指す（選好が最大の財のインデックスを選択）\n",
    "        pointing = {agent: torch.argmax(preferences[agent]).item() for agent in remaining_agents}\n",
    "        \n",
    "        visited = set()\n",
    "        cycle_found = False\n",
    "        \n",
    "        for agent in list(remaining_agents):\n",
    "            if agent in visited:\n",
    "                continue\n",
    "            cycle = []\n",
    "            current = agent\n",
    "            \n",
    "            while current not in visited:\n",
    "                visited.add(current)\n",
    "                cycle.append(current)\n",
    "                if pointing[current] not in owner_of:\n",
    "                    break  # 無効な所有者ならループを抜ける\n",
    "                next_owner = owner_of[pointing[current]]\n",
    "                current = next_owner\n",
    "            \n",
    "            # サイクル発見時、アイテム交換を確定\n",
    "            if current in cycle:\n",
    "                cycle_start = cycle.index(current)\n",
    "                cycle = cycle[cycle_start:]\n",
    "                \n",
    "                for i in range(len(cycle)):\n",
    "                    agent_id = cycle[i]\n",
    "                    item_id = pointing[agent_id]\n",
    "                    allocation[agent_id] = torch.zeros(m)  # 以前の所有をクリア\n",
    "                    allocation[agent_id, item_id] = 1  # 新しい所有をセット\n",
    "                    del owner_of[item_id]  # アイテムを市場から除去\n",
    "                \n",
    "                remaining_agents -= set(cycle)  # 交換完了エージェントを削除\n",
    "                cycle_found = True\n",
    "                break  # 1つのサイクルが処理されたら次のループへ\n",
    "        \n",
    "        # どのサイクルも見つからない場合、安全のためブレーク\n",
    "        if not cycle_found:\n",
    "            break\n",
    "    \n",
    "    return allocation\n",
    "\n",
    "# サンプルデータ\n",
    "def make_pref(n, m):\n",
    "    \"\"\"\n",
    "    各エージェントのランダムな希望リスト（値が大きいほど好ましい）を生成\n",
    "    \"\"\"\n",
    "    row = torch.linspace(1/m, 1, m)  # 1行分の値を生成\n",
    "    pref = torch.stack([row[torch.randperm(m)] for _ in range(n)])\n",
    "    return pref\n",
    "\n",
    "n, m = 4, 4\n",
    "preferences = make_pref(n, m)\n",
    "initial_owners = torch.eye(n, m)  # 各エージェントが一意のアイテムを所有しているone-hot表現\n",
    "\n",
    "# アルゴリズム実行\n",
    "final_allocation = top_trading_cycles(preferences, initial_owners)\n",
    "print(final_allocation) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m initial_owners \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(n, m)  \u001b[38;5;66;03m# 各エージェントが一意のアイテムを所有しているone-hot表現\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# アルゴリズム実行\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m final_allocation \u001b[38;5;241m=\u001b[39m \u001b[43mtop_trading_cycles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_owners\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_allocation)\n",
      "Cell \u001b[0;32mIn[37], line 33\u001b[0m, in \u001b[0;36mtop_trading_cycles\u001b[0;34m(n, m, preferences, initial_owners)\u001b[0m\n\u001b[1;32m     31\u001b[0m visited\u001b[38;5;241m.\u001b[39madd(current)\n\u001b[1;32m     32\u001b[0m cycle\u001b[38;5;241m.\u001b[39mappend(current)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpointing\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m owner_of:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# 無効な所有者ならループを抜ける\u001b[39;00m\n\u001b[1;32m     35\u001b[0m next_owner \u001b[38;5;241m=\u001b[39m owner_of\u001b[38;5;241m.\u001b[39mget(pointing[current], \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "def top_trading_cycles(n, m, preferences, initial_owners):\n",
    "    \"\"\"\n",
    "    preferences: torch.Tensor (n x m の行列, 各行はエージェントの各財への選好（値が大きいほど好ましい）)\n",
    "    initial_owners: torch.Tensor (n x m の行列, 各行はエージェントの所有アイテムを示すone-hotベクトル)\n",
    "    \"\"\"\n",
    "\n",
    "    agents = list(range(n))  # エージェントを0,1,2,...,n-1として扱う\n",
    "    allocation = torch.zeros_like(initial_owners)  # 最終的なマッチング結果（one-hot行列）\n",
    "    remaining_agents = set(agents)  # 交換が完了していないエージェント\n",
    "    \n",
    "    # 初期所有者のマッピング（財のインデックス -> エージェント）\n",
    "    owner_of = {torch.argmax(initial_owners[i]).item(): i for i in range(n)}\n",
    "    \n",
    "    while remaining_agents:\n",
    "        # 1. 各エージェントが最も好むアイテムを指す（選好が最大の財のインデックスを選択）\n",
    "        pointing = {agent: torch.argmax(preferences[agent]).item() for agent in remaining_agents}\n",
    "        \n",
    "        visited = set()\n",
    "        cycle_found = False\n",
    "        \n",
    "        for agent in list(remaining_agents):\n",
    "            if agent in visited:\n",
    "                continue\n",
    "            cycle = []\n",
    "            current = agent\n",
    "            \n",
    "            while current not in visited:\n",
    "                visited.add(current)\n",
    "                cycle.append(current)\n",
    "                if pointing[current] not in owner_of:\n",
    "                    break  # 無効な所有者ならループを抜ける\n",
    "                next_owner = owner_of.get(pointing[current], None)\n",
    "                if next_owner is None:\n",
    "                    break  # 無効な所有者ならループを抜ける\n",
    "                current = next_owner\n",
    "            \n",
    "            # サイクル発見時、アイテム交換を確定\n",
    "            if current in cycle:\n",
    "                cycle_start = cycle.index(current)\n",
    "                cycle = cycle[cycle_start:]\n",
    "                \n",
    "                for i in range(len(cycle)):\n",
    "                    agent_id = cycle[i]\n",
    "                    item_id = pointing[agent_id]\n",
    "                    allocation[agent_id] = torch.zeros(m)  # 以前の所有をクリア\n",
    "                    allocation[agent_id, item_id] = 1  # 新しい所有をセット\n",
    "                \n",
    "                # アイテムを市場から除去\n",
    "                for agent_id in cycle:\n",
    "                    item_id = pointing[agent_id]\n",
    "                    if item_id in owner_of:\n",
    "                        del owner_of[item_id]\n",
    "                \n",
    "                remaining_agents -= set(cycle)  # 交換完了エージェントを削除\n",
    "                cycle_found = True\n",
    "                break  # 1つのサイクルが処理されたら次のループへ\n",
    "        \n",
    "        # どのサイクルも見つからない場合、安全のためブレーク\n",
    "        if not cycle_found:\n",
    "            break\n",
    "    \n",
    "    return allocation\n",
    "\n",
    "# サンプルデータ\n",
    "def make_pref(n, m):\n",
    "    \"\"\"\n",
    "    各エージェントのランダムな希望リスト（値が大きいほど好ましい）を生成\n",
    "    \"\"\"\n",
    "    row = torch.linspace(1/m, 1, m)  # 1行分の値を生成\n",
    "    pref = torch.stack([row[torch.randperm(m)] for _ in range(n)])\n",
    "    return pref\n",
    "\n",
    "n, m = 4, 4\n",
    "preferences = make_pref(n, m)\n",
    "initial_owners = torch.eye(n, m)  # 各エージェントが一意のアイテムを所有しているone-hot表現\n",
    "\n",
    "# アルゴリズム実行\n",
    "final_allocation = top_trading_cycles(n, m, preferences, initial_owners)\n",
    "print(final_allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m initial_allocation \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meye(n, m)  \u001b[38;5;66;03m# 各エージェントが一意のアイテムを所有しているone-hot表現\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# アルゴリズム実行\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m final_allocation \u001b[38;5;241m=\u001b[39m \u001b[43mtop_trading_cycles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_allocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_allocation)\n",
      "Cell \u001b[0;32mIn[38], line 33\u001b[0m, in \u001b[0;36mtop_trading_cycles\u001b[0;34m(n, m, preferences, initial_allocation)\u001b[0m\n\u001b[1;32m     31\u001b[0m visited\u001b[38;5;241m.\u001b[39madd(current)\n\u001b[1;32m     32\u001b[0m cycle\u001b[38;5;241m.\u001b[39mappend(current)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mpointing\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m owner_of:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# 無効な所有者ならループを抜ける\u001b[39;00m\n\u001b[1;32m     35\u001b[0m next_owner \u001b[38;5;241m=\u001b[39m owner_of\u001b[38;5;241m.\u001b[39mget(pointing[current], \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "def top_trading_cycles(n, m, preferences, initial_allocation):\n",
    "    \"\"\"\n",
    "    preferences: torch.Tensor (n x m の行列, 各行はエージェントの各財への選好（値が大きいほど好ましい）)\n",
    "    initial_owners: torch.Tensor (n x m の行列, 各行はエージェントの所有アイテムを示すone-hotベクトル)\n",
    "    \"\"\"\n",
    "\n",
    "    agents = list(range(n))  # エージェントを0,1,2,...,n-1として扱う\n",
    "    allocation = torch.zeros_like(initial_allocation)  # 最終的なマッチング結果（one-hot行列）\n",
    "    remaining_agents = set(agents)  # 交換が完了していないエージェント\n",
    "    \n",
    "    # 初期所有者のマッピング（財のインデックス -> エージェント）\n",
    "    owner_of = {torch.argmax(initial_allocation[i]).item(): i for i in range(n)}\n",
    "    \n",
    "    while remaining_agents:\n",
    "        # 1. 各エージェントが最も好むアイテムを指す（選好が最大の財のインデックスを選択）\n",
    "        pointing = {agent: torch.argmax(preferences[agent]).item() for agent in remaining_agents}\n",
    "        \n",
    "        visited = set()\n",
    "        cycle_found = False\n",
    "        \n",
    "        for agent in list(remaining_agents):\n",
    "            if agent in visited:\n",
    "                continue\n",
    "            cycle = []\n",
    "            current = agent\n",
    "            \n",
    "            while current not in visited:\n",
    "                visited.add(current)\n",
    "                cycle.append(current)\n",
    "                if pointing[current] not in owner_of:\n",
    "                    break  # 無効な所有者ならループを抜ける\n",
    "                next_owner = owner_of.get(pointing[current], None)\n",
    "                if next_owner is None:\n",
    "                    break  # 無効な所有者ならループを抜ける\n",
    "                current = next_owner\n",
    "            \n",
    "            # サイクル発見時、アイテム交換を確定\n",
    "            if current in cycle:\n",
    "                cycle_start = cycle.index(current)\n",
    "                cycle = cycle[cycle_start:]\n",
    "                \n",
    "                for i in range(len(cycle)):\n",
    "                    agent_id = cycle[i]\n",
    "                    item_id = pointing[agent_id]\n",
    "                    allocation[agent_id] = torch.zeros(m)  # 以前の所有をクリア\n",
    "                    allocation[agent_id, item_id] = 1  # 新しい所有をセット\n",
    "                \n",
    "                # アイテムを市場から除去\n",
    "                for agent_id in cycle:\n",
    "                    item_id = pointing[agent_id]\n",
    "                    if item_id in owner_of:\n",
    "                        del owner_of[item_id]\n",
    "                \n",
    "                remaining_agents -= set(cycle)  # 交換完了エージェントを削除\n",
    "                cycle_found = True\n",
    "                break  # 1つのサイクルが処理されたら次のループへ\n",
    "        \n",
    "        # どのサイクルも見つからない場合、安全のためブレーク\n",
    "        if not cycle_found:\n",
    "            break\n",
    "    \n",
    "    return allocation\n",
    "\n",
    "# サンプルデータ\n",
    "def make_pref(n, m):\n",
    "    \"\"\"\n",
    "    各エージェントのランダムな希望リスト（値が大きいほど好ましい）を生成\n",
    "    \"\"\"\n",
    "    row = torch.linspace(1/m, 1, m)  # 1行分の値を生成\n",
    "    pref = torch.stack([row[torch.randperm(m)] for _ in range(n)])\n",
    "    return pref\n",
    "\n",
    "n, m = 4, 4\n",
    "preferences = make_pref(n, m)\n",
    "initial_allocation = torch.eye(n, m)  # 各エージェントが一意のアイテムを所有しているone-hot表現\n",
    "\n",
    "# アルゴリズム実行\n",
    "final_allocation = top_trading_cycles(n, m, preferences, initial_allocation)\n",
    "print(final_allocation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
